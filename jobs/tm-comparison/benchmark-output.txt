JMH Benchmarks Results

Module: ArjunaJTA/jta
Pattern: com.arjuna.ats.jta.xa.performance.*StoreBenchmark.*
Run arguments: -t 1 -r 25 -f 2 -wi 5 -i 5
Run output:
"Benchmark","Mode","Threads","Samples","Score","Score Error (99.9%)","Unit"
"com.arjuna.ats.jta.xa.performance.HQStoreBenchmark.testHQStore","thrpt",1,10,3182.843337,18.020066,"ops/s"
"com.arjuna.ats.jta.xa.performance.JDBCStoreBenchmark.testJDBCStore","thrpt",1,10,32.848168,11.049033,"ops/s"
"com.arjuna.ats.jta.xa.performance.ShadowNoFileLockStoreBenchmark.testShadowNoFileLockStore","thrpt",1,10,2133.139386,144.832189,"ops/s"
"com.arjuna.ats.jta.xa.performance.VolatileStoreBenchmark.testVolatileStore","thrpt",1,10,177616.558642,5479.630215,"ops/s"
JMH Benchmarks Results

Module: ArjunaJTA/jta
Pattern: com.arjuna.ats.jta.xa.performance.*StoreBenchmark.*
Run arguments: -t 24 -r 20 -f 1 -wi 3 -i 5
Run output:
"Benchmark","Mode","Threads","Samples","Score","Score Error (99.9%)","Unit"
"com.arjuna.ats.jta.xa.performance.HQStoreBenchmark.testHQStore","thrpt",24,5,77976.036458,245.836180,"ops/s"
"com.arjuna.ats.jta.xa.performance.JDBCStoreBenchmark.testJDBCStore","thrpt",24,5,331.542891,210.856453,"ops/s"
"com.arjuna.ats.jta.xa.performance.ShadowNoFileLockStoreBenchmark.testShadowNoFileLockStore","thrpt",24,5,13733.304355,331.358689,"ops/s"
"com.arjuna.ats.jta.xa.performance.VolatileStoreBenchmark.testVolatileStore","thrpt",24,5,1044827.248844,3035.930517,"ops/s"
JMH Benchmarks Results

Module: ArjunaJTA/jta
Pattern: com.arjuna.ats.jta.xa.performance.*StoreBenchmark.*
Run arguments: -t 240 -r 20 -f 1 -wi 3 -i 5
Run output:
"Benchmark","Mode","Threads","Samples","Score","Score Error (99.9%)","Unit"
"com.arjuna.ats.jta.xa.performance.HQStoreBenchmark.testHQStore","thrpt",240,5,367259.255081,19555.261301,"ops/s"
"com.arjuna.ats.jta.xa.performance.JDBCStoreBenchmark.testJDBCStore","thrpt",240,5,321.357224,221.626068,"ops/s"
"com.arjuna.ats.jta.xa.performance.ShadowNoFileLockStoreBenchmark.testShadowNoFileLockStore","thrpt",240,5,10550.859522,257.758412,"ops/s"
"com.arjuna.ats.jta.xa.performance.VolatileStoreBenchmark.testVolatileStore","thrpt",240,5,1008317.899411,32028.083071,"ops/s"
JMH Benchmarks Results

Module: ArjunaJTA/jta
Pattern: com.arjuna.ats.jta.xa.performance.*StoreBenchmark.*
Run arguments: -t 1600 -r 20 -f 1 -wi 3 -i 5
Run output:
"Benchmark","Mode","Threads","Samples","Score","Score Error (99.9%)","Unit"
"com.arjuna.ats.jta.xa.performance.HQStoreBenchmark.testHQStore","thrpt",1600,5,370711.802385,25606.810662,"ops/s"
"com.arjuna.ats.jta.xa.performance.JDBCStoreBenchmark.testJDBCStore","thrpt",1600,5,239.878143,72.087964,"ops/s"
"com.arjuna.ats.jta.xa.performance.ShadowNoFileLockStoreBenchmark.testShadowNoFileLockStore","thrpt",1600,5,8110.566994,1073.281767,"ops/s"
"com.arjuna.ats.jta.xa.performance.VolatileStoreBenchmark.testVolatileStore","thrpt",1600,5,1951069.725455,4941279.396256,"ops/s"
Sun 29 Dec 13:01:42 GMT 2019
Platform: Linux unused 3.10.0-1062.1.1.el7.x86_64 #1 SMP Tue Aug 13 18:39:59 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux
Processor: model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz
Number of Cores: 24
Blog Text
=========
/home/hudson/workspace/narayana-performance
In this release we compare ourselves against four other leading open source competitor products with a view to checking that the release remains competitive. Results are produced using JMH (a micro benchmark harness created by the OpenJDK project team available from http://openjdk.java.net/projects/code-tools/jmh/). 

We have attempted to configure each product on an equal footing by choosing sensible defaults for each tunable parameter and by ensuring that recovery is enabled, although we do configure narayana with the journal store, which is our best performing transaction log storage mechanism. If you have any recommendations for other transaction managers or how to tune the configuration then please let us know so that we can update our test job. 

The benchmark runs a transaction containing two dummy resources.

We will let the figures speak for themselves, suffice to say that when more and more threads are thrown at the workload we scale better showing that we have excellent control over parallelism. The actual figures are: 

Threads           A           B           C           D
      1        3182          32        2133      177616
     24       77976         331       13733     1044827
    240      367259         321       10550     1008317
   1600      370711         239        8110     1951069

GENERATED IMAGE FILE TO /home/hudson/workspace/narayana-performance/benchmark.png
